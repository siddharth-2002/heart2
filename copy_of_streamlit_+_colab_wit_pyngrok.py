# -*- coding: utf-8 -*-
"""Copy of Streamlit + Colab wit pyngrok

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gj3P6pmUFKtkpU90ErNGPygbpiHVl_a0
"""

! pip install streamlit -q

"""Write the cell python code into an app.py file"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import numpy as np
# import pandas as pd
# import matplotlib.pyplot as plt
# import seaborn as sns
# from sklearn.model_selection import train_test_split, GridSearchCV
# from sklearn.preprocessing import StandardScaler
# from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score
# from sklearn.linear_model import LogisticRegression
# from sklearn.tree import DecisionTreeClassifier
# from imblearn.over_sampling import SMOTE
# from imblearn.under_sampling import RandomUnderSampler
# from imblearn.pipeline import Pipeline
# from sklearn.feature_selection import SelectFromModel
# from sklearn.ensemble import RandomForestClassifier
# from collections import Counter
# 
# # Set up Streamlit page
# st.set_page_config(page_title="Heart Disease Prediction", layout="wide")
# st.sidebar.title("Navigation")
# page = st.sidebar.selectbox("Select a page", ["Home", "Upload Data", "Data Cleaning", "Data Visualization", "Prediction"])
# 
# def display_home():
#     """Display the homepage with a link to the Upload Data page."""
#     st.markdown("""
#     <style>
#     .header {
#         font-size: 36px;
#         color: #2F4F4F;
#         font-weight: bold;
#     }
#     .subheader {
#         font-size: 24px;
#         color: #4682B4;
#         font-weight: bold;
#     }
#     .text {
#         font-size: 18px;
#         color: #333333;
#     }
#     .link {
#         color: #FF6347;
#         font-weight: bold;
#     }
#     </style>
#     """, unsafe_allow_html=True)
# 
#     st.markdown("<p class='header'>Welcome to Heart Disease Prediction</p>", unsafe_allow_html=True)
#     st.markdown("<p class='text'>This app allows you to upload data, clean and visualize it, and make predictions regarding heart disease.</p>", unsafe_allow_html=True)
# 
#     st.markdown("""
#     <p class='subheader'>Use the navigation menu on the left to get started:</p>
#     <ul>
#         <li class='text'><b>Upload Data:</b> Upload your CSV file with heart disease data.</li>
#         <li class='text'><b>Data Cleaning:</b> Clean the data by handling missing values and feature selection.</li>
#         <li class='text'><b>Data Visualization:</b> Visualize the data before and after balancing.</li>
#         <li class='text'><b>Prediction:</b> Use the cleaned and balanced data to predict the risk of heart disease.</li>
#     </ul>
#     <p class='text'>Click on '<span class='link'>Upload Data</span>' in the navigation menu to begin.</p>
#     """, unsafe_allow_html=True)
# 
# def display_upload_data():
#     """Display the upload data page and process the uploaded file."""
#     st.title("Upload Data")
#     uploaded_file = st.file_uploader("Choose a CSV file", type="csv")
#     if uploaded_file is not None:
#         df = pd.read_csv(uploaded_file)
#         st.write("### Data Overview")
#         st.write(df.head())
#         st.session_state.df = df  # Save DataFrame to session state
#         st.write("Data uploaded successfully!")
# 
# def display_data_cleaning():
#     """Display the data cleaning page and handle missing values."""
#     if 'df' not in st.session_state:
#         st.warning("Please upload data first.")
#     else:
#         st.title("Data Cleaning")
#         df = st.session_state.df
# 
#         st.write("### Initial Data Overview")
#         st.write(df.head())
# 
#         # Data Preprocessing
#         if 'education' in df.columns:
#             df.drop(['education'], axis=1, inplace=True)
#         missing_data = df.isnull().sum()
#         total_percentage = (missing_data.sum() / df.shape[0]) * 100
#         st.write(f'Total percentage of missing data: {round(total_percentage, 2)}%')
# 
#         # Handle missing values
#         df.dropna(axis=0, inplace=True)
#         st.session_state.df = df  # Save cleaned DataFrame to session state
# 
#         st.write("### Cleaned Data")
#         st.write(df.head())
# 
# def display_data_visualization():
#     """Display data visualization page and handle feature selection."""
#     if 'df' not in st.session_state:
#         st.warning("Please clean the data first.")
#     else:
#         st.title("Data Visualization")
#         df = st.session_state.df
# 
#         # Feature selection
#         X = df.iloc[:, :-1]
#         y = df['TenYearCHD']
# 
#         # Fit a RandomForest model to the data
#         model = RandomForestClassifier(n_estimators=1000, n_jobs=-1, class_weight='balanced')
#         model.fit(X, y)
# 
#         # Select important features
#         selector = SelectFromModel(model, threshold="mean", prefit=True)
#         X_new = selector.transform(X)
#         top_features = X.columns[selector.get_support()].tolist()
# 
#         st.write("### Top Features Selected:")
#         st.write(top_features)
# 
#         X = df[top_features]
#         y = df['TenYearCHD']
# 
#         # SMOTE for balancing
#         over = SMOTE(sampling_strategy=0.8)
#         under = RandomUnderSampler(sampling_strategy=0.8)
#         steps = [('o', over), ('u', under)]
#         pipeline = Pipeline(steps=steps)
#         X_smote, y_smote = pipeline.fit_resample(X, y)
# 
#         num_before = dict(Counter(y))
#         num_after = dict(Counter(y_smote))
# 
#         st.write(f"### Numbers Before SMOTE:")
#         st.write(num_before)
#         st.write(f"### Numbers After SMOTE:")
#         st.write(num_after)
# 
#         # Data Visualization
#         labels = ["Negative Cases", "Positive Cases"]
#         fig, ax = plt.subplots(figsize=(15, 6))
#         sns.barplot(x=labels, y=list(num_before.values()), ax=ax)
#         ax.set_title("Numbers Before Balancing")
#         st.pyplot(fig)
# 
#         fig, ax = plt.subplots(figsize=(15, 6))
#         sns.barplot(x=labels, y=list(num_after.values()), ax=ax)
#         ax.set_title("Numbers After Balancing")
#         st.pyplot(fig)
# 
# def display_prediction():
#     """Display the prediction page and handle model training and prediction."""
#     if 'df' not in st.session_state:
#         st.warning("Please clean the data first.")
#     else:
#         st.title("Heart Disease Prediction")
#         df = st.session_state.df
# 
#         # Feature selection
#         X = df.iloc[:, :-1]
#         y = df['TenYearCHD']
# 
#         # Fit a RandomForest model to the data
#         model = RandomForestClassifier(n_estimators=1000, n_jobs=-1, class_weight='balanced')
#         model.fit(X, y)
# 
#         # Select important features
#         selector = SelectFromModel(model, threshold="mean", prefit=True)
#         X_new = selector.transform(X)
#         top_features = X.columns[selector.get_support()].tolist()
# 
#         X = df[top_features]
#         y = df['TenYearCHD']
# 
#         # SMOTE for balancing
#         over = SMOTE(sampling_strategy=0.8)
#         under = RandomUnderSampler(sampling_strategy=0.8)
#         steps = [('o', over), ('u', under)]
#         pipeline = Pipeline(steps=steps)
#         X_smote, y_smote = pipeline.fit_resample(X, y)
# 
#         # Train-test split and scaling
#         X_new = pd.DataFrame(X_smote, columns=top_features)
#         X_new['TenYearCHD'] = y_smote
#         X = X_new[top_features]
#         y = X_new['TenYearCHD']
# 
#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
#         scaler = StandardScaler()
#         X_train_scaled = scaler.fit_transform(X_train)
#         X_test_scaled = scaler.transform(X_test)
# 
#         # Model selection
#         model_type = st.selectbox("Select Model", ["Logistic Regression", "Decision Tree"])
# 
#         if model_type == "Logistic Regression":
#             st.subheader("Logistic Regression")
#             penalty = st.selectbox("Penalty", ['l1', 'l2'])
#             C = st.slider("C", 0.01, 100.0, 1.0)
#             class_weight = st.selectbox("Class Weight", ['balanced', None])
# 
#             params = {'penalty': [penalty], 'C': [C], 'class_weight': [class_weight]}
#             logistic_clf = GridSearchCV(LogisticRegression(solver='liblinear'), param_grid=params, cv=10)
#             logistic_clf.fit(X_train_scaled, y_train)
#             st.write("### Best Parameters:")
#             st.write(logistic_clf.best_params_)
# 
#             logistic_predict = logistic_clf.predict(X_test_scaled)
#             log_accuracy = accuracy_score(y_test, logistic_predict)
#             st.write(f"### Accuracy: {round(log_accuracy * 100, 2)}%")
# 
#             cm = confusion_matrix(y_test, logistic_predict)
#             conf_matrix = pd.DataFrame(data=cm, columns=['Predicted:0', 'Predicted:1'], index=['Actual:0', 'Actual:1'])
#             fig, ax = plt.subplots(figsize=(8, 5))
#             sns.heatmap(conf_matrix, annot=True, fmt='d', cmap="YlGnBu", ax=ax)
#             st.pyplot(fig)
# 
#             fpr, tpr, _ = roc_curve(y_test, logistic_clf.predict_proba(X_test_scaled)[:, 1])
#             roc_auc = roc_auc_score(y_test, logistic_clf.predict_proba(X_test_scaled)[:, 1])
#             fig, ax = plt.subplots(figsize=(8, 5))
#             ax.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
#             ax.plot([0, 1], [0, 1], color='red', linestyle='--')
#             ax.set_xlim([0.0, 1.0])
#             ax.set_ylim([0.0, 1.05])
#             ax.set_xlabel('False Positive Rate')
#             ax.set_ylabel('True Positive Rate')
#             ax.set_title('Receiver Operating Characteristic')
#             ax.legend(loc='lower right')
#             st.pyplot(fig)
# 
#         elif model_type == "Decision Tree":
#             st.subheader("Decision Tree")
#             max_depth = st.slider("Max Depth", 1, 20, 5)
#             min_samples_split = st.slider("Min Samples Split", 2, 20, 2)
#             min_samples_leaf = st.slider("Min Samples Leaf", 1, 20, 1)
# 
#             params = {'max_depth': [max_depth], 'min_samples_split': [min_samples_split], 'min_samples_leaf': [min_samples_leaf]}
#             tree_clf = GridSearchCV(DecisionTreeClassifier(), param_grid=params, cv=10)
#             tree_clf.fit(X_train_scaled, y_train)
#             st.write("### Best Parameters:")
#             st.write(tree_clf.best_params_)
# 
#             tree_predict = tree_clf.predict(X_test_scaled)
#             tree_accuracy = accuracy_score(y_test, tree_predict)
#             st.write(f"### Accuracy: {round(tree_accuracy * 100, 2)}%")
# 
#             cm = confusion_matrix(y_test, tree_predict)
#             conf_matrix = pd.DataFrame(data=cm, columns=['Predicted:0', 'Predicted:1'], index=['Actual:0', 'Actual:1'])
#             fig, ax = plt.subplots(figsize=(8, 5))
#             sns.heatmap(conf_matrix, annot=True, fmt='d', cmap="YlGnBu", ax=ax)
#             st.pyplot(fig)
# 
#             fpr, tpr, _ = roc_curve(y_test, tree_clf.predict_proba(X_test_scaled)[:, 1])
#             roc_auc = roc_auc_score(y_test, tree_clf.predict_proba(X_test_scaled)[:, 1])
#             fig, ax = plt.subplots(figsize=(8, 5))
#             ax.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
#             ax.plot([0, 1], [0, 1], color='red', linestyle='--')
#             ax.set_xlim([0.0, 1.0])
#             ax.set_ylim([0.0, 1.05])
#             ax.set_xlabel('False Positive Rate')
#             ax.set_ylabel('True Positive Rate')
#             ax.set_title('Receiver Operating Characteristic')
#             ax.legend(loc='lower right')
#             st.pyplot(fig)
# 
#         # Prediction Input
#         st.subheader("Input Data for Prediction")
#         input_data = []
#         for feature in top_features:
#             input_value = st.number_input(f"Enter value for {feature}", value=0.0)
#             input_data.append(input_value)
# 
#         if st.button("Predict"):
#             input_data = np.array(input_data).reshape(1, -1)
#             input_data_scaled = scaler.transform(input_data)
#             prediction_proba = logistic_clf.predict_proba(input_data_scaled)[:, 1]
#             prediction = logistic_clf.predict(input_data_scaled)
# 
#             st.write("### Prediction Result")
#             st.write("Probability of having heart disease:", round(prediction_proba[0], 2))
# 
#             # Categorize the probability
#             if prediction_proba[0] > 0.75:
#                 risk_level = "High"
#             elif prediction_proba[0] > 0.50:
#                 risk_level = "Normal"
#             else:
#                 risk_level = "Low"
# 
#             st.write(f"Risk Level: {risk_level}")
# 
#             # Plotting the prediction probability
#             fig, ax = plt.subplots(figsize=(8, 5))
#             ax.bar(["Risk Level"], [prediction_proba[0]], color=['red' if risk_level == "High" else 'orange' if risk_level == "Normal" else 'green'])
#             ax.set_ylim([0, 1])
#             ax.set_ylabel('Probability')
#             ax.set_title('Prediction Probability')
#             st.pyplot(fig)
# 
#         # Exit Button
#         if st.button("Exit to Home"):
#             st.session_state.page = "Home"
# 
# if page == "Home":
#     display_home()
# elif page == "Upload Data":
#     display_upload_data()
# elif page == "Data Cleaning":
#     display_data_cleaning()
# elif page == "Data Visualization":
#     display_data_visualization()
# elif page == "Prediction":
#     display_prediction()
#

! pip install pyngrok

from pyngrok import ngrok

ngrok.set_auth_token("2kSMEjbtpSqaySGoeRsmMETovI1_4YTh1t2yxcnzBpVbthvpp") #ngrok.com

!nohup streamlit run app.py --server.port 80 &
url = ngrok.connect(addr='80')  # Change 'port' to 'addr'
print(url)

!nohup streamlit run app.py --server.port 80 &
# Use 'addr' instead of 'port' for ngrok.connect
url = ngrok.connect(addr='80')
print(url)

ngrok.connect(addr='8080')  # Change 'port' to 'addr'

from pyngrok import ngrok

tunnels = ngrok.get_tunnels()
tunnels

# try:
#     # Block until CTRL-C or some other terminating event
#     ngrok_process.proc.wait()
# except KeyboardInterrupt:
#     print(" Shutting down server.")

#     ngrok.kill()

"""Run streamlit using `localtunnel`

npm installation would take some time for the first time
"""

# prompt: DEPLOYTHE   ABOVE CODE

!streamlit run app.py & npx localtunnel --port 8501